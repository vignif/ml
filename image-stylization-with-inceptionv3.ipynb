{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1122,"sourceType":"modelInstanceVersion","modelInstanceId":969,"modelId":123},{"sourceId":1123,"sourceType":"modelInstanceVersion","modelInstanceId":970,"modelId":123},{"sourceId":1124,"sourceType":"modelInstanceVersion","modelInstanceId":971,"modelId":123},{"sourceId":1125,"sourceType":"modelInstanceVersion","modelInstanceId":972,"modelId":123}],"dockerImageVersionId":30387,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Stylize Your Images In 5 Minutes\n\nDemo developed by [Sayak Paul](https://twitter.com/RisingSayak).\n\nNeural style transfer is one of the most interesting applications of deep learning. We've created a demo to help you recreate your images in the style of famous artists. \n\n![](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/table.png)\n\nThe image and code id adapted from [this tutorial](https://www.tensorflow.org/lite/models/style_transfer/overview). ","metadata":{"id":"ZMpWwQOT8rzG"}},{"cell_type":"code","source":"from IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nfrom io import BytesIO\nimport numpy as np\nimport requests","metadata":{"id":"ciYyUYVZT4IA","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Choose a style image from the options below ðŸŽ†\n\nSTYLE_IMAGE_NAME = 'IMAGE_2' #@param ['IMAGE_1', 'IMAGE_2', 'IMAGE_3', 'IMAGE_4', 'IMAGE_5']\n\ncorresponding_url = {\n    'IMAGE_1': 'https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg',\n    'IMAGE_2': 'https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg',\n    'IMAGE_3': 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Tsunami_by_hokusai_19th_century.jpg/1024px-Tsunami_by_hokusai_19th_century.jpg',\n    'IMAGE_4': 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Edvard_Munch%2C_1893%2C_The_Scream%2C_oil%2C_tempera_and_pastel_on_cardboard%2C_91_x_73_cm%2C_National_Gallery_of_Norway.jpg/800px-Edvard_Munch%2C_1893%2C_The_Scream%2C_oil%2C_tempera_and_pastel_on_cardboard%2C_91_x_73_cm%2C_National_Gallery_of_Norway.jpg',\n    'IMAGE_5': 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/757px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'\n}\n\nstyle_image_path = tf.keras.utils.get_file(STYLE_IMAGE_NAME + \".jpg\", corresponding_url[STYLE_IMAGE_NAME])\nprint(\"Style image downloaded!\")","metadata":{"id":"3qttuI19VKOZ","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<center><img src = 'https://i.ibb.co/Tmnwnbc/Untitled-Diagram.png'></img></center>","metadata":{"id":"Wu4KVB0m5f1U"}},{"cell_type":"code","source":"def load_image_from_url(url):\n    response = requests.get(url)\n    image = Image.open(BytesIO(response.content))\n    return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify the URL of the image you want to stylize\n\nimg_url = \"https://images.pexels.com/photos/6477261/pexels-photo-6477261.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"content_image = load_image_from_url(img_url)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can upload as many images as you would want to but we will only pick the last uploaded one. ","metadata":{"id":"iOdyUkmZ6Caq"}},{"cell_type":"code","source":"# Load the images\n# Function to load an image from a file, and add a batch dimension.\ndef load_img(path_to_img):\n  img = tf.io.read_file(path_to_img)\n  img = tf.io.decode_image(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  img = img[tf.newaxis, :]\n\n  return img\n\n# Function to load an image from a file, and add a batch dimension.\ndef load_content_img(image_pixels):\n    if image_pixels.shape[-1] == 4:\n        image_pixels = Image.fromarray(image_pixels)\n        img = image_pixels.convert('RGB')\n        img = np.array(img)\n        img = tf.convert_to_tensor(img)\n        img = tf.image.convert_image_dtype(img, tf.float32)\n        img = img[tf.newaxis, :]\n        return img\n    elif image_pixels.shape[-1] == 3:\n        img = tf.convert_to_tensor(image_pixels)\n        img = tf.image.convert_image_dtype(img, tf.float32)\n        img = img[tf.newaxis, :]\n        return img\n    elif image_pixels.shape[-1] == 1:\n        raise Error('Grayscale images not supported! Please try with RGB or RGBA images.')\n    print('Exception not thrown')\n\n# Function to pre-process by resizing an central cropping it.\ndef preprocess_image(image, target_dim):\n  # Resize the image so that the shorter dimension becomes 256px.\n  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n  short_dim = min(shape)\n  scale = target_dim / short_dim\n  new_shape = tf.cast(shape * scale, tf.int32)\n  image = tf.image.resize(image, new_shape)\n\n  # Central crop the image.\n  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n\n  return image\n\n# Convert the content image from Bytes to NumPy array.\ncontent_image = np.array(content_image)\n\n# Load the input images.\ncontent_image = load_content_img(content_image)\nstyle_image = load_img(style_image_path)\nprint('Images loaded up!')","metadata":{"id":"WyENTFmggM19","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Point to the model files\nstyle_predict_path = '/kaggle/input/arbitrary-image-stylization-inceptionv3/tflite/dynamic-shapes-int8-predict/1/1.tflite'\nstyle_transform_path = '/kaggle/input/arbitrary-image-stylization-inceptionv3/tflite/dynamic-shapes-int8-transfer/1/1.tflite'","metadata":{"id":"lUDZZN7Gxaz3","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stylize image ðŸ¥\n\ncontent_blending_ratio = 0 #@param {type:\"slider\", min:0, max:1, step:0.1}\n#@markdown You're encouraged to play with the different values of `content_blending_ratio`.\n\ncontent_image_size = 350 #@param {type:\"slider\", min:192, max:512, step:1}\n\n# Preprocess the input images.\npreprocessed_content_image = preprocess_image(content_image, content_image_size)\npreprocessed_style_image = preprocess_image(style_image, 256)\n\nprint('Preprocessing the style and the content images...')\nprint('Style image shape:', preprocessed_style_image.shape)\nprint('Content image shape:', preprocessed_content_image.shape)\n\ndef imshow(image, title=None):\n  if len(image.shape) > 3:\n    image = tf.squeeze(image, axis=0)\n\n  plt.imshow(image)\n  if title:\n    plt.title(title)\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(1, 3, 1)\nimshow(preprocessed_content_image, 'Content Image')\n\nplt.subplot(1, 3, 2)\nimshow(preprocessed_style_image, 'Style Image')\n\n# Function to run style prediction on preprocessed style image.\ndef run_style_predict(preprocessed_style_image):\n  # Load the model.\n  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n\n  # Set model input.\n  interpreter.allocate_tensors()\n  input_details = interpreter.get_input_details()\n  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n\n  # Calculate style bottleneck.\n  interpreter.invoke()\n  style_bottleneck = interpreter.tensor(\n      interpreter.get_output_details()[0][\"index\"]\n      )()\n\n  return style_bottleneck\n\n# Calculate style bottleneck for the preprocessed style image.\nprint('Calculating style bottleneck...')\nstyle_bottleneck = run_style_predict(preprocessed_style_image)\nprint('Style Bottleneck Shape:', style_bottleneck.shape)\nprint('Stylizing image. It should not take more than three minutes...')\n\n# Run style transform on preprocessed style image\ndef run_style_transform(style_bottleneck, preprocessed_content_image):\n  # Load the model.\n  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n\n  # Set model input.\n  input_details = interpreter.get_input_details()\n  for index in range(len(input_details)):\n    if input_details[index][\"name\"]=='content_image':\n      index = input_details[index][\"index\"]\n      interpreter.resize_tensor_input(index, [1, content_image_size, content_image_size, 3])\n  interpreter.allocate_tensors()\n\n  # Set model inputs.\n  for index in range(len(input_details)):\n    if input_details[index][\"name\"]=='Conv/BiasAdd':\n      interpreter.set_tensor(input_details[index][\"index\"], style_bottleneck)\n    elif input_details[index][\"name\"]=='content_image':\n      interpreter.set_tensor(input_details[index][\"index\"], preprocessed_content_image)\n  interpreter.invoke()\n\n  # Transform content image.\n  stylized_image = interpreter.tensor(\n      interpreter.get_output_details()[0][\"index\"]\n      )()\n\n  return stylized_image\n\n# Calculate style bottleneck of the content image.\nstyle_bottleneck_content = run_style_predict(\n    preprocess_image(content_image, 256)\n)\n\n# Blend the style bottleneck of style image and content image\nstyle_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n                           + (1 - content_blending_ratio) * style_bottleneck\n\n# Stylize the content image using the style bottleneck.\nstylized_image = run_style_transform(style_bottleneck_blended, preprocessed_content_image)\n\n# Visualize the output.\nplt.subplot(1, 3, 3)\nimshow(stylized_image, 'Stylized Image')","metadata":{"id":"sBNjdwyXlx_B","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Credit: https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Style_Transfer_Demo_InceptionV3_Dynamic_Shape.ipynb","metadata":{}}]}